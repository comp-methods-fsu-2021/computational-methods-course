# Computational Methods in the Humanities
## Will Hanley, whanley@fsu.edu
### HIS 6934-0003, Wednesday 9-12

This course is a practical introduction to computational research methods. It trains graduate students in digital analysis of the kinds of primary materials used in history, literature, religion, classics, and related fields. Students will learn to transform closed textual materials (such as PDFs and microfilms) into open formats, then experiment with methods to analyse and enrich those materials. Students are encouraged to work with primary materials from their own specialized fields of research focus. We will also do some limited reading of theoretical work related to the methods we learn. Prior knowledge of computational methods is not required.

## Course Objectives
By the end of this course, students will have

- gained practical experience with dozens of tools (both simple and complex) that deploy computational research methods, and be able to articulate opinions on the virtues and limitations of these tools
- practiced conceiving of the data potential of certain primary sources in their field, and experimenting with that potential
- learned different formats for the presentation and visualization of data, and to articulate critique of data presentations appearing in the secondary literature
- developed confidence to follow tutorials and ask questions related to their computational research needs
- produced a web presence (including a website) showcasing the products of their research

## Required Materials
### In hard copy:
- Claire Lemercier and Claire Zalc, [*Quantitative Methods in the Humanities: An Introduction*](https://www.upress.virginia.edu/title/5168) (University of Virginia Press, 2019). [companion website](https://quanthum.hypotheses.org/)
- Ted Underwood, [*Distant Horizons: Digital Evidence and Literary Change*](https://press.uchicago.edu/ucp/books/book/chicago/D/bo35853783.html) (University of Chicago Press, 2019).
- Kieran Healy, [*Data Visualization: A Practical Introduction*](https://press.princeton.edu/books/hardcover/9780691181615/data-visualization) (Princeton University Press, 2019). [companion website](https://socviz.co/)

### Online:
- Catherine D’Ignazio and Lauren Klein, [*Data Feminism*](https://data-feminism.mitpress.mit.edu/pub/frfa9szd/release/3?readingCollection=0cd867ef) (MIT Press, 2020).

## Grading
**Weekly exercises (5% per week) 70%** 

Each week's meeting will begin with a review of the previous week's exercise. You will submit the deliverable by midnight on the night before class. You will document your work process, and offer a brief assessment of the research potential and problems you see in the exercise, as well the next steps you might pursue. These exercises will be graded on a completion basis. Satisfactory work receives full marks. Unsatisfactory work can be resubmitted until it is satisfactory.

**Website 30%** 

Every student will produce a website containing her or his transformed and enriched primary material, analysis, and documentation. This is a cumulative, standalone, public project; it is not an amalgum of the weekly exercises. It is a showcase of the skills you build and the research sensibilities you bring to your work. It will include discussion, where appropriate, of secondary literature on computational methods (including material we read in class). The website will be due at the end of the semester.

## Schedule

### Jan. 6: Introduction

**Exercise:** Find a text of interest to you already in rough digital form, e.g. from [archive.org](https://archive.org/); perform quick transformations, use simple web-based tools.

**Quick Tool:** [Sublime Text](https://www.sublimetext.com/), [Voyant](https://voyant-tools.org/), [Palladio](http://hdlab.stanford.edu/palladio/)

---

### Jan. 13: Corpora

**Exercise:** Identify a texual primary source in closed format and transform it into plain text. Students are encouraged to identify a source from their own field of interest that includes quantitative as well as qualitative material (ideally in the form of lists). Suggested data-rich sources with broad coverage:

- Almanach de Gotha, in French and German. [Hathi has 1880 - 1897 from Penn State]
- English language equivalents include Burke's Peerage (UK), Social Register (US).

**Reading:** Lemercier and Zalc

**Quick Tools:** Adobe Acrobat, Google Docs

---

### Jan. 20: Infrastructure
**Exercise:** Sign up for various computational services, and post material from last week's source to Github and Wikipedia.

**Slow Tools:** Github, Stack Overflow, Wikipedia, Zenodo

---

### Jan. 27: Open Formats I
**Exercise:** Post a cleaned open format version of your primary source, regularized using regular expressions. Post a file documenting the cleaning process.

**Suggested tutorial:** Dennis Tenen and Grant Wythoff, "Sustainable Authorship in Plain Text using Pandoc and Markdown," The Programming Historian 3 (2014), https://doi.org/10.46430/phen0041.

**Quick Tool:** [Regular expressions](https://regexr.com)

---

### Feb. 3: Cleaning I
**Exercise:** Post a cleaned, regularized set of tables derived from a transformation of your primary source.

**Reading:** Lemercier and Zalc

**Quick Tool:** Google Sheets, Microsoft Excel, [Breve](http://hdlab.stanford.edu/breve/)
**Slow Tool:** [Open Refine](https://openrefine.org/)

---

### Feb. 10: Visualization I
**Exercise:** Share a range of visualizations of your primary source.

**Reading:** Healy

**Quick Tool:** [Raw Graphs](https://app.rawgraphs.io/), [Google Data Studio](https://datastudio.google.com/overview)
**Slow Tool:** [Tableau](https://public.tableau.com/en-us/s/)

---

### Feb. 17: Quantification I
**Exercise:** Share an R workbook visualizing material from your primary source.

**Reading:** Lemercier and Zalc

**Slow Tool:** [R Studio](https://rstudio.com/)

---

### Feb. 24: Sharing I
**Exercise:** Make a preliminary version of your Hugo or Jekyll website live.

**Slow Tool:** [Hugo](https://gohugo.io/) or [Jekyll](https://jekyllrb.com/)

---

### Mar. 3: Text Mining
**Exercise:** Produce word frequency comparison between your primary source and appropriate reference sources.

**Reading:** Underwood

**Quick Tool:** [TopicModelingTool](https://senderle.github.io/topic-modeling-tool/documentation/2017/01/06/quickstart.html)

---

### Mar. 10: Categorization
**Exercise:** Upload some data byproducts to Wikidata.

**Reading:** D’Ignazio and Klein

**Slow Tools:** SPARQL, Wikidata

---

### Mar. 17: Open Formats II
**Exercise:** Enriched, cleaned primary source posted to website.

---

### Mar. 24: Quantification II
**Exercise:** Enriched, cleaned data tables derived from primary source posted to website.

---

### Mar. 31: Cleaning II
**Exercise:** Documentation posted to website.

---

### Apr. 7: Visualization II
**Exercise:** Data visualizations and workbooks posted to website.

---

### Apr. 14: Sharing II
**Exercise:** No weekly exercise is due following this class. The final version of websites will be due at the end of the following week (April 23).